{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe87e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def pad_or_truncate(arr: np.ndarray, target_len: int) -> np.ndarray:\n",
    "\n",
    "    T, D = arr.shape\n",
    "    if T == target_len:\n",
    "        return arr\n",
    "    elif T < target_len:\n",
    "        pad_len = target_len - T\n",
    "        pad = np.zeros((pad_len, D), dtype=arr.dtype)\n",
    "        return np.concatenate([arr, pad], axis=0)\n",
    "    else:  # T > target_len\n",
    "        return arr[:target_len]\n",
    "\n",
    "\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "uids = []\n",
    "for i in ['dev_clean', 'train_clean_100', 'dev_other', 'test_clean', 'test_other']:\n",
    "    folder = f\"librispeech_ppg_raw/{i}\"\n",
    "    for filename in os.listdir(folder):\n",
    "        if not filename.endswith(\".npy\"):\n",
    "            continue\n",
    "\n",
    "        name_without_ext = filename[:-4]  # \"FAEM0_1\"\n",
    "\n",
    "        path = os.path.join(folder, filename)\n",
    "        arr = np.load(path)\n",
    "        target = np.load(f'/home/main/Desktop/librispeech_mcc/{name_without_ext[4:]}-feat.npy')\n",
    "\n",
    "\n",
    "        #i_vec = np.tile(result[uid], (arr.shape[0], 1))  # (5, 3)\n",
    "        #arr = np.hstack([arr, i_vec])\n",
    "        #arr = np.concat([arr, i_vec], axis=1)\n",
    "        arr = pad_or_truncate(arr, len(target))\n",
    "\n",
    "        X.append(arr)\n",
    "        y.append(target)\n",
    "\n",
    "        uids.append(name_without_ext[4:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd79d764",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "X = [torch.tensor(arr, dtype=torch.float32) for arr in X]\n",
    "y = [torch.tensor(arr, dtype=torch.float32) for arr in y]\n",
    "\n",
    "# X_test = [torch.tensor(arr, dtype=torch.float32) for arr in X_test]\n",
    "# y_test = [torch.tensor(arr, dtype=torch.float32) for arr in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b601aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import random\n",
    "\n",
    "# # Fix seed\n",
    "# random.seed(42)\n",
    "\n",
    "# # Random selection out of 10% in all indexs\n",
    "# num_samples = len(X)\n",
    "# test_size = int(num_samples * 0.1)\n",
    "# test_indices = random.sample(range(num_samples), test_size)\n",
    "\n",
    "# # Structure test set\n",
    "# X_test = [X[i] for i in test_indices]\n",
    "# y_test = [y[i] for i in test_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b3ee04dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_indices = list(set(range(num_samples)) - set(test_indices))\n",
    "# X = [X[i] for i in train_indices]\n",
    "# y = [y[i] for i in train_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cb4e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/20] Train Loss: 0.0380 | Val Loss: 0.0468\n",
      "[Epoch 2/20] Train Loss: 0.0273 | Val Loss: 0.0435\n",
      "[Epoch 3/20] Train Loss: 0.0255 | Val Loss: 0.0418\n",
      "[Epoch 4/20] Train Loss: 0.0246 | Val Loss: 0.0401\n",
      "[Epoch 5/20] Train Loss: 0.0236 | Val Loss: 0.0392\n",
      "[Epoch 6/20] Train Loss: 0.0226 | Val Loss: 0.0376\n",
      "[Epoch 7/20] Train Loss: 0.0221 | Val Loss: 0.0367\n",
      "[Epoch 8/20] Train Loss: 0.0213 | Val Loss: 0.0356\n",
      "[Epoch 9/20] Train Loss: 0.0206 | Val Loss: 0.0338\n",
      "[Epoch 10/20] Train Loss: 0.0201 | Val Loss: 0.0328\n",
      "[Epoch 11/20] Train Loss: 0.0196 | Val Loss: 0.0330\n",
      "[Epoch 12/20] Train Loss: 0.0191 | Val Loss: 0.0318\n",
      "[Epoch 13/20] Train Loss: 0.0187 | Val Loss: 0.0319\n",
      "[Epoch 14/20] Train Loss: 0.0182 | Val Loss: 0.0307\n",
      "[Epoch 15/20] Train Loss: 0.0178 | Val Loss: 0.0304\n",
      "[Epoch 16/20] Train Loss: 0.0177 | Val Loss: 0.0305\n",
      "[Epoch 17/20] Train Loss: 0.0173 | Val Loss: 0.0296\n",
      "[Epoch 18/20] Train Loss: 0.0172 | Val Loss: 0.0307\n",
      "[Epoch 19/20] Train Loss: 0.0175 | Val Loss: 0.0293\n",
      "[Epoch 20/20] Train Loss: 0.0171 | Val Loss: 0.0293\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "\n",
    "# hyper parameters\n",
    "input_dim = 144\n",
    "hidden_dim = 256\n",
    "output_dim = 40\n",
    "num_layers = 2\n",
    "bidirectional = True\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "num_epochs = 20\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 1. Custom Dataset\n",
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "\n",
    "# collate_fn definition\n",
    "def collate_fn_pad(batch):\n",
    "    # batch: list of tuples (x_i, y_i), where each x_i: [Ti, input_dim], y_i: [Ti, output_dim]\n",
    "    x_list, y_list = zip(*batch)  # unzip\n",
    "    lengths = [x.shape[0] for x in x_list]\n",
    "\n",
    "    # padding\n",
    "    x_padded = pad_sequence(x_list, batch_first=True)  # [batch, max_len, input_dim]\n",
    "    y_padded = pad_sequence(y_list, batch_first=True)  # [batch, max_len, output_dim]\n",
    "\n",
    "    lengths = torch.tensor(lengths, dtype=torch.long)  # [batch]\n",
    "\n",
    "    return x_padded, y_padded, lengths\n",
    "\n",
    "\n",
    "# 2. Model definition\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "class ManyToManyDBLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers, bidirectional):\n",
    "        super(ManyToManyDBLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_dim,\n",
    "            hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            bidirectional=bidirectional,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        # lengths: [batch] (CPU Tensor)\n",
    "        packed = pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        packed_out, _ = self.lstm(packed)\n",
    "        unpacked, _ = pad_packed_sequence(packed_out, batch_first=True)  # [batch, max_len, hidden_dim*2]\n",
    "        output = self.fc(unpacked)  # [batch, max_len, output_dim]\n",
    "        return output\n",
    "\n",
    "\n",
    "# 3. train/val split\n",
    "X_train, X_val, y_train, y_val, uids_train, uids_val= train_test_split(X, y,uids, test_size=0.1, random_state=42)\n",
    "\n",
    "train_dataset = SequenceDataset(X_train, y_train)\n",
    "val_dataset = SequenceDataset(X_val, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
    "                          drop_last=False, collate_fn=collate_fn_pad)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False,\n",
    "                        drop_last=False, collate_fn=collate_fn_pad)\n",
    "\n",
    "\n",
    "# 4. Prepare Train\n",
    "model = ManyToManyDBLSTM(input_dim, hidden_dim, output_dim, num_layers, bidirectional).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 5. Train Loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for xb, yb, lengths in train_loader:\n",
    "        xb, yb, lengths = xb.to(device), yb.to(device), lengths.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(xb, lengths)\n",
    "        loss = criterion(outputs, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "\n",
    "    # Validation Loop\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb, lengths in val_loader:\n",
    "            xb, yb, lengths = xb.to(device), yb.to(device), lengths.to(device)\n",
    "\n",
    "            outputs = model(xb, lengths)\n",
    "            loss = criterion(outputs, yb)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    print(f\"[Epoch {epoch+1}/{num_epochs}] Train Loss: {train_loss/len(train_loader):.4f} | Val Loss: {val_loss/len(val_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e50e9b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset = SequenceDataset(X_test, y_test)\n",
    "\n",
    "# test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False,\n",
    "#                         drop_last=False, collate_fn=collate_fn_pad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cd13edb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for xb, yb, lengths in val_loader:\n",
    "        xb, yb, lengths = xb.to(device), yb.to(device), lengths.to(device)\n",
    "\n",
    "        outputs = model(xb, lengths)\n",
    "        y_pred.append(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "90c71912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3967"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(uids_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31bcd8d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2428-83705-0009'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uids_val[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e091f5d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([838, 144]) torch.Size([838, 127])\n"
     ]
    }
   ],
   "source": [
    "print(X[10].shape, y[10].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5248d0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파일이 존재합니다.\n",
      "2428-83705-0009\n",
      "dev-clean\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pyworld as pw\n",
    "import pysptk\n",
    "import soundfile as sf\n",
    "import scipy.ndimage\n",
    "import torch\n",
    "\n",
    "# diffsptk MLPG import\n",
    "from diffsptk import MLPG\n",
    "import diffsptk\n",
    "#wav_path = \"kaldi/egs/timit/s5/data/TIMIT/TEST/DR4/MLLL0/SX283.WAV\"\n",
    "\n",
    "test_index = 100\n",
    "\n",
    "uid = uids_val[test_index]\n",
    "uid_split = uid.split('-')\n",
    "\n",
    "import os\n",
    "\n",
    "for i in ['dev-clean', 'dev-other', 'test-clean', 'test-other', 'train-clean-100']:\n",
    "    wav_path = f\"/home/main/Desktop/kaldi/egs/librispeech/s5/data/{i}/LibriSpeech/{i}/{uid_split[0]}/{uid_split[1]}/{uid}.flac\"\n",
    "\n",
    "    if os.path.exists(wav_path):\n",
    "        print(f\"File already exists.\\n{uid}\\n{i}\")\n",
    "        break\n",
    "    else:\n",
    "        print(\"File doesn't exist.\")\n",
    "\n",
    "\n",
    "x, fs = sf.read(wav_path)\n",
    "frame_period = 10.0\n",
    "\n",
    "# 1. WORLD 분석\n",
    "f0, timeaxis = pw.harvest(x, fs, frame_period=frame_period)\n",
    "f0 = pw.stonemask(x, f0, timeaxis, fs)\n",
    "sp = pw.cheaptrick(x, f0, timeaxis, fs)\n",
    "ap = pw.d4c(x, f0, timeaxis, fs)\n",
    "\n",
    "frame_period = 10.0\n",
    "fs = 16000\n",
    "\n",
    "#features = np.hstack([mcc, delta, delta_delta])\n",
    "features_torch = y_pred[test_index].float().to('cpu')#.unsqueeze(0)\n",
    "features_torch = torch.concat([features_torch[:,:,:40], features_torch[:,:,42:42+40], features_torch[:,:,84:84+40]], axis=2)\n",
    "#features_torch = torch.from_numpy(features).float().unsqueeze(0)  # shape: (1, T, 3*D)\n",
    "\n",
    "T = features_torch.shape[1]\n",
    "mlpg = MLPG(size=T)  \n",
    "smoothed = mlpg(features_torch)  # shape: (1, T, D)\n",
    "\n",
    "smoothed_mcc = smoothed.squeeze(0).numpy().T  # shape: (D, T)\n",
    "\n",
    "\n",
    "fftlen = 1024\n",
    "\n",
    "sp_recon = np.array([\n",
    "    pysptk.mc2sp(m, alpha=0.42, fftlen=fftlen)\n",
    "    for m in y_pred[test_index].squeeze(0).cpu().numpy()\n",
    "])\n",
    "\n",
    "\n",
    "wav = pw.synthesize(f0, sp_recon.astype(np.double), ap, fs, frame_period=frame_period)\n",
    "\n",
    "sf.write(f\"reconstructed_mlpg_{test_index}.wav\", wav, fs)\n",
    "sf.write(f\"reconstructed_mlpg_{test_index}_real.wav\", x, fs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e763b874",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bir",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
